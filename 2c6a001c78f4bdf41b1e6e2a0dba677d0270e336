{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "a188a7ab_54cb5da1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 29
      },
      "lineNbr": 0,
      "author": {
        "id": 8038
      },
      "writtenOn": "2023-05-03T20:02:34Z",
      "side": 1,
      "message": "I think one problem with using the SourceTracker is that it only updates when new packets are decoded, so it doesn\u0027t necessary reflect what is played out.\n\nOne suggestion is to use the audio level that is computed in ChannelReceive instead that measures the audio samples that are played out. GetSpeechOutputLevelFullRange (https://source.chromium.org/chromium/chromium/src/+/refs/heads/main:third_party/webrtc/audio/channel_receive.h;l\u003d107;drc\u003de0e0d24aaa54727dc0a8bc4b159ccdf80d3f5d8d) has some smoothing built in that may or may not be desirable.\n\nWe could calculate the energy using only the frame directly otherwise. This is already done in the mixer so it would be nice to avoid doing it multiple times: https://source.chromium.org/chromium/chromium/src/+/refs/heads/main:third_party/webrtc/modules/audio_mixer/audio_mixer_impl.cc;l\u003d53;drc\u003de0e0d24aaa54727dc0a8bc4b159ccdf80d3f5d8d",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e955e854_893fb62b",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 29
      },
      "lineNbr": 0,
      "author": {
        "id": 5508
      },
      "writtenOn": "2023-05-05T13:42:08Z",
      "side": 1,
      "message": "`[SourceTracker] only updates when new packets are decoded`\n- Actually ST does get updated even when neteq is not in the picture and playout is not active:\n\nhttps://source.chromium.org/chromium/chromium/src/+/refs/heads/main:third_party/webrtc/audio/channel_receive.cc;l\u003d332\n\nI did consider `GetSpeechOutputLevelFullRange()` too but beyond the playout aspect of neteq there are more reasons why SourceTracker is a good fit.\n\nhta@ and discussed this particular case too btw and here are some of our reasonings that\u0027s hopefully useful:\n\nThe muted state of a remote _source_ (notably, not _track_) conceptually represents the source state before playout. One way to think of it is that \u0027muted\u0027 represents state at the input of a source rather than the output. Output being what\u0027s then feeding playout. E.g. with a microphone, the mute state reflects the OS mute state (or hw) of the mic, which is state that the application does not control (at least not via webrtc). The `enabled` property on the other hand is what the application can use to apply its own control to mute the output of the audio track.\n\nSimilarly, for a remote track, the state that\u0027s outside of the application\u0027s control, is owned by the sender. The mute state from the sender, should ideally match with what the receiver reads it as. `GetSpeechOutputLevelFullRange()` can report non-0 values for a fully muted remote sources, which is because of a local source (neteq) can affect the level when playout is active and generate noise (which technically is an implementation detail of webrtc). Whether or not that\u0027s a bug doesn\u0027t matter for this case, but it\u0027s important to note since if we were to check the state at that point, it could make a receiver\u0027s mute state be different than sender\u0027s for exactly the same audio packets.\n\nAnother aspect I was thinking about that\u0027s maybe good to be aware of, but is more about performance, is that GetSpeechOutputLevelFullRange() currently is prone to contention between the audio thread and network thread. This has been the case for as long as I can remember, but I\u0027d of course like to not add _more_ opportunities for contention. SourceTracker won\u0027t cause that.\n\nBeyond that, taking into account other architectural changes that are currently in-flight (especially as it relates to Chrome), some of the audio source/track APIs/states are currently tied to the \u0027worker\u0027 thread. They, along with getCSRCs, need to migrate from the worker to the signaling thread. That\u0027s because the worker and network threads are becoming one and the same and we don\u0027t want to block the network thread. Once we do that, it will further allow us to improve performance in Chrome by allowing this data to live on the js thread and even be queryable without involving the signaling thread (as is done for some properties already). The data in SourceTracker is already being managed in a lock-free way, which helps.\n\nOne last thing to consider is if we want to open up ways for applications to bring their own jitter buffer implementations, then having this part of the wire-up for an audio source to be connected to the source before neteq (rather than dependent on it), could make things architecturally easier down the line.",
      "parentUuid": "a188a7ab_54cb5da1",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "2f185fa5_0e4aac72",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 29
      },
      "lineNbr": 0,
      "author": {
        "id": 8038
      },
      "writtenOn": "2023-05-05T16:06:44Z",
      "side": 1,
      "message": "Thanks, I think what you are saying around reflecting the remote \"source\" state makes sense. This is how RTCRtpSynchronizationSource is implemented for example.\n\nReading the spec here: https://www.w3.org/TR/webrtc/#mediastreamtrack-network-use\n\nAccording to this, any incoming packet should \"unmute\" the track and muting is triggered by receiving RTCP_BYE or timeout in absence of any packets.\n\nMaybe the spec is designed for video and not the audio use case where muting is typically done by setting `track.enabled \u003d false` instead of stop sending completely. Do we need to update the spec so that it makes more sense for audio? Or are there other parts of the spec that I have missed?\n\nAnother thing to consider is what to do when the sender doesn\u0027t use the audio level header extension?",
      "parentUuid": "e955e854_893fb62b",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "8d3db8cb_09ab5bbf",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 29
      },
      "lineNbr": 0,
      "author": {
        "id": 8038
      },
      "writtenOn": "2023-05-05T16:06:44Z",
      "side": 1,
      "message": "Adding Harald to our discussion around the spec.",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "94788084_a857db03",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 29
      },
      "lineNbr": 0,
      "author": {
        "id": 5634
      },
      "writtenOn": "2023-05-08T13:06:55Z",
      "side": 1,
      "message": "1) the moving of callbacks between tracks looks like a snake ready to bite you. I don\u0027t see the point, and it makes life more complicated.\n\n2) since this CL doesn\u0027t do rate limiting, it\u0027s risky for all the reasons we\u0027ve discussed. Please put it behind a feature flag.",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "5f259ba8_b0ee1c78",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 29
      },
      "lineNbr": 0,
      "author": {
        "id": 5508
      },
      "writtenOn": "2023-05-08T14:49:12Z",
      "side": 1,
      "message": "1) I\u0027m assuming you\u0027re referring to how unsignaled SSRCs are managed in voice engine. I\u0027ll shed some light on that in the other comments.\n\n2) Will follow up with a feature flag. I\u0027ll also follow up with a CL that handles rate limiting. Note that additional wiring-up is required in Chrome to hook this up to the eventual `muted` property, so just flagging that since this CL doesn\u0027t change the existing behavior.",
      "parentUuid": "94788084_a857db03",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "c31d4a31_f4148f6c",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 29
      },
      "lineNbr": 0,
      "author": {
        "id": 5508
      },
      "writtenOn": "2023-05-08T14:49:12Z",
      "side": 1,
      "message": "It seems to me that we could clarify/sharpen the language in the spec and that it would be helpful to do so.\n\nAs far as `track.enabled \u003d false` goes, from what I know, it should work the same way for audio and video in basic terms. The `muted` property might change regardless of the `enabled` property though. I.e. you could have an unmuted source connected to disabled track (or vice versa).\n\nAs far as other parts of the spec, for local streams, there are some useful examples given for the muted property. There\u0027s still vagueness there when it comes to practicalities when writing the code, but the use cases are still helpful to understand the intent (and how it provides value to the application):\n\n```\nThere can be several reasons for a MediaStreamTrack to be muted: the user pushing a physical mute button on the microphone, the user closing a laptop lid with an embedded camera, the user toggling a control in the operating system, the user clicking a mute button in the User Agent chrome, the User Agent (on behalf of the user) mutes, etc.\n```\n\nA laptop lid for a camera doesn\u0027t necessarily mean that the application would stop receiving frames. Pressing the mute button on a microphone similarly might only be detectable from the application by receiving 0\u0027d buffers (as opposed to knowing about the device\u0027s muted state).\n\nGood point about absence of the audio level header. I suppose getContributingSources doesn\u0027t do much in that case üòê",
      "parentUuid": "2f185fa5_0e4aac72",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0a6d1983_06fc608e",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 29
      },
      "lineNbr": 0,
      "author": {
        "id": 5634
      },
      "writtenOn": "2024-05-31T06:40:12Z",
      "side": 1,
      "message": "Talk about a CL returning from the grave of forgetfulness....\n\nNo, the spec results from long discussions considering both audio and video.\n\nCurrent link is https://w3c.github.io/webrtc-pc/#mediastreamtrack-network-use - don\u0027t use the tr/ version, it\u0027s not updated with fixes.\n\nMute is a temporary state; ended is a permanent state.\nThere\u0027s nothing in the RTP spec that permits telling the receiver \"I\u0027ve temporarily stopped sending\", except for TMMBN, which the spec doesn\u0027t allow, or negotiating the track from sendrecv/sendonly to recvonly/inactive (that\u0027s the reference to \"muted by negotiation\").\nBYE is sometimes sent without the track ending, for instance when changing SSRCs, so we didn\u0027t want to end the track when it happens.\n\nI don\u0027t see a distinction between video and audio that we need to reflect here; Guido\u0027s been dealing with mute state in the absence of samples in other cases, so CCing him on the CL.\n\nPlease comment further if there\u0027s more that needs saying.",
      "parentUuid": "c31d4a31_f4148f6c",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "c7b8c6ba_d07c17a3",
        "filename": "media/engine/webrtc_voice_engine.cc",
        "patchSetId": 29
      },
      "lineNbr": 2227,
      "author": {
        "id": 5634
      },
      "writtenOn": "2023-05-08T13:06:55Z",
      "side": 1,
      "message": "This behavior seems surprising to me. It means that if you add a stream, set a callback, and then get an unsignaled stream, the callback will now fire on a stream different from the one you added it to.\n\nConsider requiring a new callback to be set for each stream, and not doing the wandering-callback-dance.",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "d86e20d0_5f8ae472",
        "filename": "media/engine/webrtc_voice_engine.cc",
        "patchSetId": 29
      },
      "lineNbr": 2227,
      "author": {
        "id": 5508
      },
      "writtenOn": "2023-05-08T14:49:12Z",
      "side": 1,
      "message": "Ah the wandering-callback-dance üòÑ\n\nThis is the design of the class actually and part of the complexity it manages - for unsignaled streams that is. There are two ways that the class operates:\n\n* \"I don\u0027t know about SSRCs, so just do the default thing\". This part of the implementation is the surprising part and specific for what is \u0027default\u0027.\n* The other works exactly as you\u0027d expect and does not involve the dance.\n\nThe comment I\u0027m adding in this CL just explains the existing behaviour. See calls to `SetRawAudioSink` for example as well as how the class manages the \u0027default\u0027 audio stream (e.g. what `GetUnsignaledSsrc()` does).\n\nIf we were to redesign the class, then I think that all the magic around the default dance would require a significant amount of changes (including API). But I don\u0027t think that there\u0027s much value in it as it stands since the audio code has different assumptions around playout than the video code does. I\u0027m also not sure what concrete problem we\u0027d be trying to solve (or even that the final outcome would be _less_ complicated). In general the \u0027default\u0027 concept abstracts away this complexity from the pov of the user of the class when the \"default\" methods are used.",
      "parentUuid": "c7b8c6ba_d07c17a3",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "5c96b409_201d85ff",
        "filename": "modules/rtp_rtcp/source/source_tracker.h",
        "patchSetId": 29
      },
      "lineNbr": 70,
      "author": {
        "id": 5634
      },
      "writtenOn": "2023-05-08T13:06:55Z",
      "side": 1,
      "message": "Didn\u0027t we invent an \"SSRC\" class for use instead of raw uint32_t?",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "1747fed5_ae4389a2",
        "filename": "modules/rtp_rtcp/source/source_tracker.h",
        "patchSetId": 29
      },
      "lineNbr": 70,
      "author": {
        "id": 5508
      },
      "writtenOn": "2023-05-08T14:49:12Z",
      "side": 1,
      "message": "I don\u0027t _think_ we have a class for it but we frequently use `absl::optional\u003cuint32_t\u003e` for it (to avoid assuming that 0 is not an SSRC).\n\nWe did invent a class (StreamId) for 16 bit sctp identifiers - maybe that\u0027s the one you\u0027re thinking of?",
      "parentUuid": "5c96b409_201d85ff",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9a978c90_d76d960e",
        "filename": "modules/rtp_rtcp/source/source_tracker.h",
        "patchSetId": 29
      },
      "lineNbr": 74,
      "author": {
        "id": 5634
      },
      "writtenOn": "2023-05-08T13:06:55Z",
      "side": 1,
      "message": "Do we ever want to do the audio level callback on anything except SSRC?\nFiring \"mute\" events on a track should not happen on anything but the SSRC; it\u0027s not muted unless it\u0027s silent, the state of the CSRCs doesn\u0027t matter.",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "afea26e5_bb42ce0b",
        "filename": "modules/rtp_rtcp/source/source_tracker.h",
        "patchSetId": 29
      },
      "lineNbr": 74,
      "author": {
        "id": 5508
      },
      "writtenOn": "2023-05-08T14:49:12Z",
      "side": 1,
      "message": "Moving beyond just the `muted` property, I do think it would be useful to know the unmixed audio level of a CSRC down the line. But we don\u0027t have a way for an audio source to represent a CSRC but it sounds like something to think about in terms of what an API could look like.",
      "parentUuid": "9a978c90_d76d960e",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "30f6aa56_866a501b",
        "filename": "pc/audio_track.cc",
        "patchSetId": 29
      },
      "lineNbr": 68,
      "author": {
        "id": 5634
      },
      "writtenOn": "2023-05-08T13:06:55Z",
      "side": 1,
      "message": "Please guard this behind a feature flag.",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "815a9d79_ba023b2c",
        "filename": "pc/audio_track.cc",
        "patchSetId": 29
      },
      "lineNbr": 68,
      "author": {
        "id": 5508
      },
      "writtenOn": "2023-05-08T14:49:12Z",
      "side": 1,
      "message": "Will follow up",
      "parentUuid": "30f6aa56_866a501b",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "11240615_d97b7e23",
        "filename": "pc/remote_audio_source.cc",
        "patchSetId": 29
      },
      "lineNbr": 33,
      "author": {
        "id": 8038
      },
      "writtenOn": "2023-05-05T16:06:44Z",
      "side": 1,
      "message": "This feels out of place here. This should be handled in the source tracker or before it. If the receive stream is active, then updates to the source tracker will be in-order (i.e. this is redundant). In the other case, https://www.w3.org/TR/webrtc/#dom-rtcrtpcontributingsource says that packets must be processed in order, so the check should probably be in the source tracker.",
      "range": {
        "startLine": 33,
        "startChar": 0,
        "endLine": 33,
        "endChar": 76
      },
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ac04dd26_87308d5b",
        "filename": "pc/remote_audio_source.cc",
        "patchSetId": 29
      },
      "lineNbr": 33,
      "author": {
        "id": 5508
      },
      "writtenOn": "2023-05-08T14:49:12Z",
      "side": 1,
      "message": "Yes agree that it makes more sense as part of SourceTracker. I\u0027m actually not if this happens in practice but since I did not find the code that would do the ordering in the case where playout isn\u0027t active (no neteq) so I added this and the test for it. I\u0027ll take a look at moving it over to SourceTracker.",
      "parentUuid": "11240615_d97b7e23",
      "range": {
        "startLine": 33,
        "startChar": 0,
        "endLine": 33,
        "endChar": 76
      },
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "cdd278be_4c632eb9",
        "filename": "pc/remote_audio_source.cc",
        "patchSetId": 29
      },
      "lineNbr": 124,
      "author": {
        "id": 5634
      },
      "writtenOn": "2023-05-08T13:06:55Z",
      "side": 1,
      "message": "Or perhaps the feature flag should go here.",
      "revId": "2c6a001c78f4bdf41b1e6e2a0dba677d0270e336",
      "serverId": "58829da1-049c-39fb-b951-ebdcd0984767"
    }
  ]
}